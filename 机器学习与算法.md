# 机器学习与算法

> 学习机器学习，走进数据分析的第一步

## 第一章（基本概念）



### 基本术语

| 术语                         | 含义                                                         |
| ---------------------------- | ------------------------------------------------------------ |
| 记录                         | 一对括号内的数据                                             |
| 数据集                       | 一组数据                                                     |
| 示例、样本、特征向量         | 记录中的描述值                                               |
| 样例                         | 拥有标记的示例                                               |
| 标记                         | 分类的结果                                                   |
| 标记空间、输出空间           | 所有标记的集合                                               |
| 属性、特征                   | 性别、年龄                                                   |
| 属性值                       | 属性的取值                                                   |
| 属性空间、样本空间、输入空间 | 属性的集合                                                   |
| 学习、训练                   | 从数据中获得模型的过程                                       |
| 训练数据                     | 训练过程中使用的数据                                         |
| 训练集                       | 训练样本组成的集合                                           |
| 假设                         | 学习的结果（找到的潜在规律），学习的目标就是为了找到最好的假设 |
| 真实、真相                   | 规律本身                                                     |
| 学习器                       | 采用的模型                                                   |
| 测试                         | 使用学习器预测的过程                                         |
| 测试样本、测试集             | 被预测的样本                                                 |
| 泛化能力                     | 学习地模型适用于新样本的能力                                 |
| 验证集                       | 使用最终模型进行预测的样本                                   |

### 分类

1. 学习方法不同：监督学习、非监督学习 

监督学习：有标记的样本，如房价预测（回归问题）、癌症的诊断（分类）

* 算法：线性回归，对数几率，决策树、支持向量机、贝叶斯、神经网络

非监督学习：无标记样本，如新闻分组（分类）

* 聚类算法、概率图模型、降维与度量学习等（原型（K均值等）、密度、层次）

半监督学习

> 给出算法能够判断算法属于哪一个类型

> 分类依据（具体）：监督学习通过有标记的数据对其进行分类或者预测，而非监督学习是直接对数据进行建模，没有给定事先标记过的训练集，也不知道输入数据对应的输出结果是什么。



## 第二章（模型的选择）



**评价泛化能力**：错误率和精度的计算

误差：实际输出和真实值的差异

泛化误差：在新样本的误差

经验误差/训练误差：训练集的误差



### 过拟合

解决方案：

1. 减少特征的数量（增加特征不一定能够提高，且测试集的正确率不一定会提高）

2. 添加正则化，所有的特征都需要加入正则项。

> 注意：加入了正则化以后不一定能提高泛化性能，当正则化参数过大的时候会出现欠拟合，过小没影响。



### 模型的选择

评估的方法



**交叉验证法(k折交叉验证）**：注重在新样本上的泛化性能

* 划分子集，分层采样（尽可能保持数据分布一致性）

* 最终的结果是k次的测试结果的平均值



性能度量

**错误率和精度**

* 错误率：`E = a / M`
* 精度：`1 - E`



**查全率和查准率**

* 混淆矩阵：

| 真实情况\预测情况 | 正例 | 反例 |
| ----------------- | ---- | ---- |
| 正例              | TP   | FN   |
| 反例              | FP   | TN   |



解释含义，列一下公式

* 查准率（精确率）P：强调准确率，预测真实的样本中的实际真实结果的比率
  $$
  p = \frac{TP}{TP+FN}
  $$

* 查全率（召回率）R：强调覆盖率，最终预测正确的结果占真实正确结果的比率，比如查找犯罪嫌疑人。

$$
R = \frac{TP}{TP+FP}
$$

两者相互对立：PR图，BEP



度量回归任务的性能：**均方误差**

$$
\frac{1}{m} \sum_{i=1}^m (f(x_i) - y_i)^2
$$
**F1度量**
$$
F_1 = \frac{2PR}{P+R}
$$
**偏差和反差**

对于回归和分类

* 偏差：度量了预测结果和真实结果的偏离程度，偏差反映了性能，刻画了学习算法的拟合能力。例如：boosting关注的是偏差，不断纠正之前模型的错误

$$
bias^2=(\hat{f}(x)-y)^2
$$

> 形容数据跟我们期望的中心差的有多远，算是有监督额

* 方差：度量了同样大小的训练集的变动导致算法性能的变化，刻画了数据扰动带来的影响。例如：bagging：自助采样生成了多个训练集，更加关注了方差。

$$
var(x)=E(f(x;D)-\hat{f}(x))
$$

> 形容数据分散程度的，算是无监督的，客观的指标

* 噪声：度量了当前任务上任何学习算法所能达到的期望泛化误差下界，刻画了样本的标记与真实标记的区别。

关系：偏差和反差存在冲突

1. 训练不足，偏差大，欠拟合

2. 不断训练之后，方差占主导，过拟合



## 第三章（逻辑回归）

模型的形式，学习率等



### 线性回归

1. 多元线性回归（预测）

$$
f(x_i) = w^T x_i + b
$$

2. 对数回归

$$
lny = w^T + b
$$

为了找到合适的参数`\theta0`和`\theta1`

* 最小二乘法：基于均方误差最小化进行模型求解的方法

* 损失函数：实际预测结果和真实结果之间的均方和的平均值

* 梯度下降：不断地迭代，更新参数值，减小损失函数的值J(`theta`)

* 主要参数：`alpha`，`theta0`，`theta1`

* `\alpha`：学习率，不能过小（导致收敛率过低）也不能太大（可能产生发散或者震荡，增大误差）



### 对数几率回归（分类）

使用到了**sigmoid**函数作为跃迁函数
$$
sigmoid(z) = \frac{1}{1+e^{-z}}
$$


### 多分类学习

> 将多分类拆分为多个二分类任务求解：

1. **OVO**:一对一：
   $$
   任意两个类别进行两两组合（全排列），总共需要\frac{N(N-1)}{2}次
   $$
   
2. **OVR**:一对多：只需要训练N个训练器，一个对其余

3. MVM：多对多：不考



## 第四章(决策树)

分而治之的思想，对样本的分析划分属性

具体过程：从根节点不断判定直到叶子节点



### 选择最优划分属性

1. 信息增益

> ID3决策树使用的是信息增益的方法

* 信息熵：度量样本集合纯度最常用的一种指标，**值越小，纯度越高。**

$$
Ent(D) = -\sum_{k=1}^{|y|}p_klog_2p_k
$$

* 使用信息增益值最大的属性作为最优划分属性。
  $$
  Gain(D,a) = Ent(D) - \sum_{v=1}^{V}\frac{D^v}{D}Ent(D^v)
  $$

* 

计算过程：先对每个属性计算其对应的信息熵，然后再根据总类别的信息熵和子属性的信息熵的权重，计算信息增益，最后比较所有信息增益。



### 剪枝

1. 预剪枝：在决策树生成的过程中，<u>在每个结点划分之前</u>进行估计，如果当前结点的划分不能够提升决策树的泛化性能，就停止划分并标记为叶子节点。

2. 后剪枝：在决策树生成完毕之后，<u>自底向上</u>对非叶子节点进行考察，如果将结点对应子树替换为叶子节点能够提升决策树的泛化性能，就替换。

| 比较   | 优点                         | 缺点           |
| ------ | ---------------------------- | -------------- |
| 预剪枝 | 直接开销低，过拟合风险降低   | 欠拟合风险增加 |
| 后剪枝 | 测试时间降低，过拟合风险降低 | 增加了开销     |



### 处理连续值

* 连续属性离散化的基本思路和常见做法

<u>二分法</u>

由二分法计算得到一个T值，小于T值得为一类，大于的为一类。



## 第五章（神经网络）



## 神经元模型

> 神经元从其他多个神经元接收到了输入信号，如果接受的信号之和比较小，没有超过神经元的阈值，神经元的细胞体就会忽略收到的信号

模拟的方法：使用`sigmoid`函数作为激活函数
$$
z_i = \sum_{i=1}^{n}w_ix_i + b (w_i为权重，b为偏置又称为偏置单元)
$$

$$
实际输出a_i = sigmoid(z_i)
$$

$$
sigmoid(z) = \frac{1}{1+e^{-z}}
$$



### 感知机和多层网络

感知机是两层神经元，输入层接受立马输出，只有一层功能神经元，只能解决**与、或、非**问题，不能解决**异或**等非线性可分的问题。



### BP算法

关于`sigmoid`函数
$$
f' = f(x)(1-f(x))
$$
BP算法的过程：

1. 初始化所有的权重和偏置，输入样本数据，计算出输出值

2. 计算出此时神经网络模型的梯度值

3. 由已知的输出值逆过来计算上一层（隐层神经元）的梯度值

4. 更新连接权值`w`,`v`和阈值`theta`和`gama`

   > `w`从神经元出去的权值
   >
   > `v`进入神经元的权值
   >
   > `theta`输出层神经元阈值
   >
   > `gama`隐层神经元阈值

5. 达到停止条件（累计误差值（梯度值）小于特定值）

$$
通过学习确定的参数数目：（特征向量维度+输出值个数+1个偏置单元）q个隐层神经元+输出值
$$

缺点：导致过拟合

解决方案：

**早停**

1. 设置一个阈值，如果训练误差连续训练a次的变换均小于b，停止训练
2. 使用验证集，如果训练误差降低，但是验证集误差升高，停止训练

**正则化**：误差目标函数中增加一项描述网络复杂度



## 第六章（SVM）

原理：求解能够正确划分各个类别且具有最大划分间隔的超平面

最大间隔：点到平面的平均距离最大



### 间隔和支持向量

$$
平面方程：w^Tx+b=0
$$

$$
点到平面的距离：r=\frac{w^Tx+b}{||w||}
$$

$$
划分的超平面的平均间隔：\gamma=\frac{2}{||w||}
$$

**支持向量**：距离超平面最近的几个点，两个异类支持向量的距离之和也就是`gamma`的值

**改变支持向量会影响SVM模型的结果，模型是由支持向量决定**

为了找到最大的间隔，需要最大化分母，也等同于最小化倒数的
$$
\min_{w,b} \frac{1}{2}||w||^2
$$
间隔不仅与`w`有关，还与`b`有关（`b`是与原点的距离）



### 对偶问题

具体的推导过程中注意

1. 矩阵乘0不为0，一定不能消去
2. `||w||`的计算是矩阵的乘法，`w'w`
3. 注意要注明所有的条件



**KKT条件**

重要性质：支持向量机解的稀疏性：训练完成后，大部分的训练样本都不需要保留，最终模型只与支持向量有关。



### 核函数

**解决线性不可分：**将样本映射到更高维的空间**(方法：引入核函数)**，让这个样本的特征值可以在高维空间可分

> 核函数：线性核、多项式核、**高斯核**、拉普拉斯、Sigmoid核



### 正则化

$$
\min_{f} \Omega(f) + C\sum_{i=1}^m l(f(x_i),y_i)
$$

1. `omega(f)` 为正则项
2. `C`惩罚参数，越大对**误分类**惩罚越大，可能出现过拟合现象；越小就越看重正则项，可能出现欠拟合



### L范数:正则化的正则化项

$$
L_0范数指向量中非0的元素的个数
$$

$$
L_1范数是指向量中各个元素绝对值之和
$$

$$
L_2范数是指向量各个元素的平方和然后求平方根
$$





## 第七章（朴素贝叶斯）

**朴素贝叶斯的假设条件：属性条件独立**

> 属性条件独立：对于所有类别，假设所有的属性都是相互独立的，也就是每一个属性独立的对分类结构产生影响

**贝叶斯定理的计算方法**
$$
P(c|x)=\frac{P(c)P(x|c)}{P(x)}=\frac{P(c)}{P(x)}\prod_{i=1}{d}P(x_i|c)
$$
**应用：将一个测试样例进行分类**

1. 计算总的样本中的各个类别的概率

   > P(好瓜=是) 

2. 计算这个样本的所有属性的取值对应的所有的类别的概率

   > P(好瓜=是|属性=A)
   >
   > P(好瓜=否|属性=A)

3. 结合所有属性计算为对应类别的概率

   > P(好瓜|样本=1) = P(好瓜=是)P(好瓜=是|属性=A)P(好瓜=是|属性=B)···P(好瓜=是|属性=？)
   >
   > P(坏瓜|样本=1)=...

4. 比较这两个概率，概率高的为最终的分类

**EM算法：计算含有隐变量的概率模型的近似估算**

提供一种**期望最大化算法**，迭代式的方法

交替计算

1. 利用当前估计的参数值来计算对数似然估计的期望值
2. 寻找能够使E部产生的似然期望最大化的参数值
3. 将M步找到的参数应用于E步，直到收敛到局部最优解



## 第八章（集成学习）



### boosting

工作机制

> 1. 先训练一个基学习器
> 2. 根据基学习器的表现对样本分布进行调整，使得之前的基学习器分错的训练样本在后续可以得到更多的关注，然后再基于调整后的样本分布来训练下一个基学习器
> 3. 重复训练的过程
> 4. 直到达到指定的值T，并将这T个基学习器进行加权组合



### bagging

思想：不断地降低结果的反差

1. 分类任务：投票法决定最终结果

2. 回归任务：平均法决定最终结果



### 随机森林

1. 属性选择：随机性

2. 随机森林 = 多个决策树 + 随机选择属性

3. 优点：属性扰动增加了随机森林的多样性，而且不出现过拟合的现象

4. 具体思路：

   > 1. 原来是选择最优属性，现在是随机选择一个属性
   >
   > 2. 在划分结点的属性也是随机选择的确定

5. 基于bagging的思想，优于bagging

   > bagging采用的是决定型决策树，要考虑决策树的所有属性，而随机森林只考虑一个属性子集



### 多样性扰动

1. 多样性越大，集成效果越好
2. 学习过程中引入多样性：
   * 数据样本
   * 输入属性
   * 输出表示
   * 算法参数进行扰动



## 第九章（聚类）

概念：将数据集中的样本划分为若干个通常不相交的子集

欧式距离：两点之间的距离

原型聚类：

1. K均值算法：

```
需要指定聚类数k
随机选择k个样本作为均值向量
分别计算其他点距离均值向量的距离，并按照距离的大小排序划分
持续这个过程直到不在改变聚类中心
```

2. 密度聚类

基于密度的聚类，假设聚类结构能够通过<u>样本的紧密程度</u>来确定。密度聚类算法从<u>样本密度的角度考虑样本之间的可连接性</u>，并基于可连接样本不断扩展聚类簇来获得最终的聚类结果。



聚类的结构可以通过密度衡量，从样本密度的角度来考虑样本之间的可连接性，基于可连接性来不断扩展聚类簇来获得最终的聚类结果。

